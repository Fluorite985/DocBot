
# DocBot ğŸ¤–  
*A fully local, free, and private AI chatbot that answers questions based on your own documents.*

---

## ğŸ“˜ Overview  
**DocBot** is a locally-run Retrieval-Augmented Generation (RAG) chatbot built using **LangChain**, **Ollama**, **ChromaDB**, and **Streamlit**. It allows you to ingest documents, generate embeddings, and query them via a **chat interface** through a **web UI**. No internet, no API keys, no cost.

---

## ğŸ§© Features  
- ğŸ§  **LLM-powered** question answering with local models via **Ollama**  
- ğŸ—ƒï¸ Document chunking, indexing, and retrieval with **LangChain** and **ChromaDB**  
- ğŸ’¬ Interactive chat via **Streamlit** web interface or terminal  
- ğŸ”’ 100% local â€” no external API calls, private by design  
- ğŸ› ï¸ Modular, lightweight, and easy to extend  

---

## ğŸ”§ Built With  
- [LangChain](https://github.com/langchain-ai/langchain)  
- [Ollama](https://ollama.com/) â€“ for running open-source LLMs locally  
- [ChromaDB](https://www.trychroma.com/) â€“ vector DB for embeddings  
- [Streamlit](https://streamlit.io/) â€“ simple, fast web UI  
- Python 3.10+

---

## âš™ï¸ Getting Started  

### âœ… Prerequisites  
- Python 3.10+  
- [Ollama installed](https://ollama.com/download) and a model pulled (e.g. `mistral`)  
- Streamlit installed (`pip install streamlit`)  
- All Python dependencies (`pip install -r requirements.txt`)

---

### ğŸ”§ Installation  
```bash
git clone https://github.com/Fluorite985/DocBot.git
cd DocBot
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

Ensure Ollama is running:
```bash
ollama run mistral
```

---

## ğŸš€ Usage

### ğŸ§± 1. Prepare your documents:
```bash
python dataprep.py --input data/*.txt --output chunks/
```

### ğŸ§  2. Start the backend (retriever + LLM wrapper):
```bash
python chat_backend.py
```

### ğŸ’¬ 3.Load up the interface:

#### Terminal Chat  
```bash
python interface.py
```

## ğŸ–¥ Project Structure  
```
DocBot/
â”œâ”€â”€ dataprep.py            # Document splitting & cleaning(Make sure to create a seperate folder)
â”œâ”€â”€ embedding_function.py  # Function to import Ollama Embeddings
â”œâ”€â”€ chat_backend.py        # Loads retriever & connects to Ollama
â”œâ”€â”€ interface.py           # Web-based chat interface using StreamLit 
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # This file
```

---

## ğŸ“ Example Use Cases  
- ğŸ“š Query summaries or answers from technical documentation  
- ğŸ§¾ Search through meeting transcripts or legal docs  
- ğŸ“ Use as a local AI study assistant

---

## ğŸ”’ Privacy & Cost  
- âœ… No cloud usage  
- âœ… No OpenAI API key needed  
- âœ… No fees, fully offline after setup

---

## ğŸ¤ Contributing  
Feel free to open issues, suggest features, or submit pull requests to improve the UI, add PDF/document support, or enhance LLM interaction.

---
